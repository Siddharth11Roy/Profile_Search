# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wThwZKXb-rebjeikg_kTsOJYpgfvS4M
"""

pip install scholarly

# from scholarly import scholarly
# import pandas as pd

# def fetch_scholar_data(name, unique_id):
#     # Search for the profile
#     search_query = scholarly.search_author(f"{name} {unique_id}")
#     try:
#         author = next(search_query, None)  # Get the first matching author
#     except StopIteration:
#         print("No matching profile found!")
#         return None

#     # Fill profile with detailed information
#     author = scholarly.fill(author)

#     # Extract data
#     profile_data = {
#         "Name": author.get("name", ""),
#         "Affiliation": author.get("affiliation", ""),
#         "Citations": author.get("citedby", 0),
#         "H-Index": author.get("hindex", 0),
#         "i10-Index": author.get("i10index", 0),
#         "Citations Per Year": author.get("cites_per_year", {})
#     }

#     # Convert dictionary into a DataFrame
#     data_df = pd.DataFrame([profile_data])
#     return data_df

# def main():
#     # Input
#     name = input("Enter the name: ")
#     unique_id = input("Enter the unique identifier (e.g., institution): ")

#     # Fetch data
#     data_df = fetch_scholar_data(name, unique_id)

#     if data_df is not None:
#         # Save to CSV
#         csv_file = f"{name}_scholar_data.csv"
#         data_df.to_csv(csv_file, index=False)
#         print(f"Data saved to {csv_file}")
#     else:
#         print("Failed to fetch data.")

# if __name__ == "__main__":
#     main()

# from scholarly import scholarly
# import pandas as pd

# def fetch_scholar_data(name, unique_id):
#     # Search for the profile
#     search_query = scholarly.search_author(f"{name} {unique_id}")
#     try:
#         author = next(search_query, None)  # Get the first matching author
#     except StopIteration:
#         print("No matching profile found!")
#         return None, None

#     # Fill profile with detailed information
#     author = scholarly.fill(author)

#     # Extract main profile data
#     profile_data = {
#         "Name": author.get("name", ""),
#         "Affiliation": author.get("affiliation", ""),
#         "Citations": author.get("citedby", 0),
#         "H-Index": author.get("hindex", 0),
#         "i10-Index": author.get("i10index", 0),
#     }

#     # Extract histogram (citations per year)
#     histogram = author.get("cites_per_year", {})
#     histogram_data = pd.DataFrame([histogram])

#     # Return as DataFrames
#     profile_df = pd.DataFrame([profile_data])
#     return profile_df, histogram_data

# def main():
#     # Input
#     name = input("Enter the name: ")
#     unique_id = input("Enter the unique identifier (e.g., institution): ")

#     # Fetch data
#     profile_df, histogram_df = fetch_scholar_data(name, unique_id)

#     if profile_df is not None and histogram_df is not None:
#         # Save to Excel file with multiple sheets
#         excel_file = f"{name}_scholar_data.xlsx"
#         with pd.ExcelWriter(excel_file) as writer:
#             profile_df.to_excel(writer, sheet_name="Profile", index=False)
#             histogram_df.to_excel(writer, sheet_name="Citations_Per_Year", index=False)

#         print(f"Data saved to {excel_file}")
#     else:
#         print("Failed to fetch data.")

# if __name__ == "__main__":
#     main()

pip install streamlit

import streamlit as st
from scholarly import scholarly
import pandas as pd

def fetch_scholar_data(name, unique_id):
    # Search for the profile
    search_query = scholarly.search_author(f"{name} {unique_id}")
    try:
        author = next(search_query, None)  # Get the first matching author
    except StopIteration:
        return None, None

    # Fill profile with detailed information
    author = scholarly.fill(author)

    # Extract main profile data
    profile_data = {
        "Name": author.get("name", ""),
        "Affiliation": author.get("affiliation", ""),
        "Citations": author.get("citedby", 0),
        "H-Index": author.get("hindex", 0),
        "i10-Index": author.get("i10index", 0),
    }

    # Extract histogram (citations per year)
    histogram = author.get("cites_per_year", {})
    histogram_data = pd.DataFrame([histogram])

    # Return as DataFrames
    profile_df = pd.DataFrame([profile_data])
    return profile_df, histogram_data

# Streamlit App
st.title("Google Scholar Data Fetcher")

# Sidebar Inputs
st.sidebar.header("Enter Author Details")
name = st.sidebar.text_input("Author Name")
unique_id = st.sidebar.text_input("Unique Identifier (e.g., Institution)")

if st.sidebar.button("Fetch Data"):
    if not name or not unique_id:
        st.error("Please provide both Name and Unique Identifier!")
    else:
        st.info("Fetching data from Google Scholar...")
        profile_df, histogram_df = fetch_scholar_data(name, unique_id)

        if profile_df is not None and histogram_df is not None:
            # Display results
            st.success("Data fetched successfully!")
            st.subheader("Profile Data")
            st.dataframe(profile_df)

            st.subheader("Citations Per Year")
            st.dataframe(histogram_df)

            # Save to Excel and provide download link
            excel_file = f"{name}_scholar_data.xlsx"
            with pd.ExcelWriter(excel_file) as writer:
                profile_df.to_excel(writer, sheet_name="Profile", index=False)
                histogram_df.to_excel(writer, sheet_name="Citations_Per_Year", index=False)

            with open(excel_file, "rb") as f:
                st.download_button(
                    label="Download Excel File",
                    data=f,
                    file_name=excel_file,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.error("Failed to fetch data. Please try again.")
